\section{Introduction}

The Raft consensus algorithm originated to simplify the 
preexisting Paxos algorithm, while at the same time, 
solving the same core problem \cite{OngaroRaft} with a 
similar efficiency. For years, Paxos had dominated 
distributed consensus. At its core it defined a way in 
which a system could come to agreement on a given state 
\cite{LamportPPT}. Though, Paxos can be incredibly hard 
to comprehend. Many papers have been published in an 
attempt to offer a clearer explanation as to how Paxos 
functions \cite{LamportSimple, MazieresPractical}, but it 
continues to be a difficult system to implement at a 
practical level.

Ultimately, these algorithms define a method for a system to agree on a state \cite{BrandFSM}. They work to build a fault tolerant approach to distributed systems, the \textit{replicated state machine} \cite{SchneiderFSM}. In this context, a group of machines replicate a single state across themselves to create a fault tolerant system, that can handle the failure of $n/2 - 1$ nodes. The essential goal of consensus in terms of the \textit{replicated state machine} is to reach a \textit{univalent} state, from any \textit{multivalent} state. Such algorithms specifically order state changes, to ensure that when applied, that all result in the same state \cite{OngaroRaft, LamportTime}. Raft also works to correct, and right, any nodes in a cluster in contradicting states. It does this via counting \texttt{election terms}, demonstrated as such:
\\
\\
We define two nodes in a cluster, with two corresponding state machines, $M$ and $N$. We also define a function, $T(S)$, of some arbitrary state machine $S$, that is its current \texttt{term}, where $T_{c}$ is the correct \texttt{term} in the cluster.
\\
\\
$$
T_{c} =
\begin{cases}
M, & T(M) > T(N)\\
N, & T(M) < T(N)\\
\varnothing, & T(M) = T(N)
\end{cases}
$$
\\
\\
In order to keep some sense of order in the cluster, Raft keeps track of the number of leader elections that have occured with the \texttt{election term}. This is a system wide tally that is used to determine when a node may be behind or have conflicting information in its log.
Many of these comparisons have to be made from node to node through heartbeat messages, that also act to check for leader liveness \cite{OngaroRaft}. But, as one might imagine, as you try to include more nodes in a cluster, the number of checks that have to be propogated to ensure an effective system drastically increases.