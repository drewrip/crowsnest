\section{Testing Consensus}

	The big draw of Raft is its practicallity. It has allowed many the opportunity to implement distributed consensus, as it was designed to be understandable. So with this is mind, we maintain a similar dogma when it comes to testing the algorithms scalability. We wanted to design a test that would accomplish two main goals: \textit{(1)} stress test the network, its throughput, and its ability to maintain consensus; \textit{(2)} realistically represent an application or use case that Raft might see in a real world system.

	With these considerations, we first decided the most common use case for this method of distributed consensus. The official Raft website contains a useful list of implementations \cite{RaftSite}. Given its capabilities, Raft is very commonly used for database replication \cite{etcd, CockroachDB, TiKV, RethinkDB}, so we decided to have our \textit{replicated state machine} be small key-value store, essentially a replicated mapping.

	We elected to use a popular open source library written in Go, \texttt{hashicorp/raft} \cite{HashicorpRaft}. Then we wrote a simple key value store \textit{replicated state machine}, into a barebones example for greater efficiency \cite{Dinghy}. We spun up a cluster of an increasing, odd, size, and run a stress test on the cluster. The key value store is initialized with 10,000 entries as shown:
	\\
	\\
	\texttt{key1: 0}
	\\
	\texttt{key2: 0}
	\\
	...
	\\
	\texttt{key10000: 0}
	\\
	\\
	Then after initializing the state machine, we start issuing requests to the network for a change in state. We go one by one, requesting a change, and a subsequent read in the value, of one key-value pair. After every 100 requests made to the network, we attempt to simulate node failures. Our script evaluates each node in the cluster. The script randomly decides whether or not said node should \textit{fail}. Independly, we give each node a 10\% chance of failure. This process of node failure in our testing we call \textit{Intentional Random Node Failure}. We then reconnect all failed nodes, after 1 request to the network has been made. By the end of one full routine, we have gone through a total of 100 \textit{Intentional Random Node Failures}, and have updated 10,000 values in our replicated key-value store such that:
	\\
	 \\
	\texttt{key1: 1}
	\\
	\texttt{key2: 2}
	\\
	...
	\\
	\texttt{key10000: 10000}
	\\
	 \\
	The metric we use to compare between tests is the time in which the this routine takes to complete. This should be fully evaluate Raft consensus via both throughput, and fault tolerance.