\section{Testing Consensus}

	The big draw of Raft is its practicallity. It has allowed many the opportunity to implement distributed consensus, as it was designed to be understandable. So with this is mind, we maintain a similar dogma when it comes to testing the algorithms scalability. We wanted to design a test that would stress test the networks throughput given a certain size, given that Raft is overwhelmingly used in creating fault tolerant databases \cite{etcd, CockroachDB, TiKV, RethinkDB}.

	With these considerations, we first decided the most common use case for this method of distributed consensus. The official Raft website contains a useful list of implementations \cite{RaftSite}. Given its capabilities, Raft is overwhelmingly used for database replication , 
	We elected to use a popular open source library written in Go, \texttt{hashicorp/raft} \cite{HashicorpRaft}. With this, we used an integer state in our cluster's state machine. We define the function $S(R)$, that is the current state of some arbitrary Raft node, $R$.

	Our testing tracks the number of successful \texttt{Apply} operations we are able to make to the replicated state in some time. The time alloted for a single test is denoted as $T_{f}$. After every state update, a barrier is called in order to ensure all of the nodes are consistent. After $T_{f}/4$ the leader of the test cluster is killed. That is to say, it is non-gracefully shutdown, will stop returning messages, and will not return to be a functioning member of the cluster at any time during the test.
	The replicated state machine is being incremented every update, such that, after $T_{f}$, given a set of Raft nodes $C$, \[\{r_{1},r_{2} \in C: S(r_{1})=S(r_{2})\}\] and the final number of applies, or commits for our test was the value of the final integer state of some arbitrary node in the cluster.

	In this specific instance we elected for a shorter testing time of 5 seconds, then of course by our procedure, the leader would be killed after 1.25 seconds \cite{Dinghy}. We use this specific procedure in the testing of both our proposed algorithm, Dinghy, and the benchmarks of pure Raft.