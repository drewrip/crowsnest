\section{Testing Consensus}

	The big draw of Raft is its practicallity. It has allowed many the opportunity to implement distributed consensus, as it was designed to be understandable. So with this is mind, we maintain a similar dogma when it comes to testing the algorithms scalability. We wanted to design a test that would stress test the networks throughput given a certain size, given that Raft is overwhelmingly used in creating fault tolerant databases \cite{etcd, CockroachDB, TiKV, RethinkDB}.

	With these considerations, we first decided the most common use case for this method of distributed consensus. The official Raft website contains a useful list of implementations \cite{RaftSite}. Given its capabilities, Raft is overwhelmingly used for database replication , 
	We elected to use a popular open source library written in Go, \texttt{hashicorp/raft} \cite{HashicorpRaft}. With this, we used an integer state in our cluster's state machine. We define the function $S(R)$, that is the current state of some arbitrary Raft node, $R$.

	Our testing tracks the time it takes for a constant number of successive \texttt{Apply} operations to take place.
	The replicated state machine is being incremented every update, such that, after $T_{f}$, given a set of Raft nodes $C$, \[\{r_{1},r_{2} \in C: S(r_{1})=S(r_{2})\}\] and the final number of applies, or commits for our test was the value of the final integer state of some arbitrary node in the cluster.

	In our specific trials we timed how long it took the cluster to reach 1000 state changes \cite{Dinghy}. We use this specific procedure in the testing of both our proposed algorithm, Dinghy, and the benchmarks of pure Raft.